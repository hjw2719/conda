{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 | Python “黑箱”：输入与输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a Python environment with a few libraries, including `dask`, all of which were specificied using a `conda` [environment.yml](../edit/environment.yml) file. To demo the environment, we'll show a simplified example of using `dask` to analyze time series data, adapted from Matthew Rocklin's excellent repo of [dask examples](https://github.com/blaze/dask-examples) — check out that repo for the full version (and many other examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入输出基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your name:Jack\n",
      "you are a boy?(y/n)y\n",
      "authorizing...\n",
      "Welcome to the matrix Mr. Jack.\n"
     ]
    }
   ],
   "source": [
    "name = input('your name:')\n",
    "gender = input('you are a boy?(y/n)')\n",
    "\n",
    "########输入##########\n",
    "\n",
    "# your name:Jack\n",
    "# you are a boy?\n",
    "\n",
    "welcome_str = 'Welcome to the matrix {prefix} {name}.'\n",
    "welcome_dic = {\n",
    "    'prefix': 'Mr.' if gender == 'y' else 'Mrs',\n",
    "    'name': name\n",
    "}\n",
    "\n",
    "print('authorizing...')\n",
    "print(welcome_str.format(**welcome_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "a + b = 12\n",
      "type of a is <class 'str'>, type of b is <class 'str'>\n",
      "a + b = 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = input()\n",
    "# 1\n",
    "b = input()\n",
    "# 2\n",
    "\n",
    "print('a + b = {}'.format(a + b))\n",
    "########## 输出 ##############\n",
    "# a + b = 12\n",
    "print('type of a is {}, type of b is {}'.format(type(a), type(b)))\n",
    "########## 输出 ##############\n",
    "# type of a is <class 'str'>, type of b is <class 'str'>\n",
    "print('a + b = {}'.format(int(a) + int(b)))\n",
    "########## 输出 ##############\n",
    "# a + b = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character. I have a dream today.\n",
    "\n",
    "I have a dream that one day down in Alabama, with its vicious racists, . . . one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers. I have a dream today.\n",
    "\n",
    "I have a dream that one day every valley shall be exalted, every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed, and all flesh shall see it together.\n",
    "\n",
    "This is our hope. . . With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day. . . .\n",
    "\n",
    "And when this happens, and when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual: \"Free at last! Free at last! Thank God Almighty, we are free at last!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 读取文件；\n",
    "2. 去除所有标点符号和换行符，并把所有大写变成小写；\n",
    "3. 合并相同的词，统计每个词出现的频率，并按照词频从大到小排序；\n",
    "4. 将结果按行输出到文件 out.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse(text):\n",
    "    \n",
    "    # 使用正则表达时取出标点符号和换行符\n",
    "    text = re.sub(r'[^\\w ]', ' ', text)\n",
    "    \n",
    "    # 转为小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 生成所有单词的列表\n",
    "    word_list = text.split(' ')\n",
    "    \n",
    "    # 去处空白单词\n",
    "    word_list = filter(None, word_list)\n",
    "    \n",
    "    # 生成单词和词频的字典\n",
    "    word_cnt = {}\n",
    "    for word in word_list:\n",
    "        if word not in word_cnt:\n",
    "            word_cnt[word] = 0\n",
    "        word_cnt[word] += 1\n",
    "        \n",
    "    # 按照词频排序\n",
    "    sorted_word_cnt = sorted(word_cnt.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return sorted_word_cnt\n",
    "\n",
    "with open('in.txt', 'r') as fin:\n",
    "    text = fin.read()\n",
    "    \n",
    "word_and_freq = parse(text)\n",
    "\n",
    "with open('out.txt', 'w') as fout:\n",
    "    for word, freq in word_and_freq:\n",
    "        fout.write('{} {}\\n'.format(word, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before json serialization\n",
      "type of params_str = <class 'str'>, params_str = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n",
      "after json deserialization\n",
      "type of original_params = <class 'dict'>, original_params = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "params = {\n",
    "    'symbol': '123456',\n",
    "    'type': 'limit',\n",
    "    'price': 123.4,\n",
    "    'amount': 23\n",
    "}\n",
    "\n",
    "params_str = json.dumps(params)\n",
    "\n",
    "print('after json serialization')\n",
    "print('type of params_str = {}, params_str = {}'.format(type(params_str), params))\n",
    "\n",
    "original_params = json.loads(params_str)\n",
    "\n",
    "print('after json deserialization')\n",
    "print('type of original_params = {}, original_params = {}'.format(type(original_params), original_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思考题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 你能否把 NLP 例子中的 word count 实现一遍？不过这次，in.txt 可能非常非常大（意味着你不能一次读取到内存中），而 output.txt 不会很大（意味着重复的单词数量很多）。提示：你可能需要每次读取一定长度的字符串，进行处理，然后再读取下一次的。但是如果单纯按照长度划分，你可能会把一个单词隔断开，所以需要细心处理这种边界情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "CHUNK_SIZE = 100\n",
    "\n",
    "def parse_word(text, last_word, word_list):\n",
    "    \n",
    "    # 使用正则表达时取出标点符号和换行符\n",
    "    text = re.sub(r'[^\\w ]', ' ', last_word + text)\n",
    "    \n",
    "    # 转为小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 生成所有单词的列表\n",
    "    cur_word_list = text.split(' ')\n",
    "    \n",
    "    # 去处空白单词\n",
    "    cur_word_list = filter(None, cur_word_list)\n",
    "    \n",
    "    return last_word\n",
    "    \n",
    "def solver():    \n",
    "    with open('in.txt', 'r') as fin:\n",
    "        word_list, last_word = [], ''\n",
    "        while True:\n",
    "            text = fin.read(CHUNK_SIZE)\n",
    "            if not text:\n",
    "                break #读取完毕跳出循环\n",
    "            last_word = parse_word(text, last_word, word_list)\n",
    "            \n",
    "            \n",
    "\n",
    "        word_and_freq = parse(text)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 生成单词和词频的字典\n",
    "    word_cnt = {}\n",
    "    for word in word_list:\n",
    "        if word not in word_cnt:\n",
    "            word_cnt[word] = 0\n",
    "        word_cnt[word] += 1\n",
    "        \n",
    "    # 按照词频排序\n",
    "    sorted_word_cnt = sorted(word_cnt.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return sorted_word_cnt\n",
    "\n",
    "    with open('out.txt', 'w') as fout:\n",
    "        for word, freq in word_and_freq:\n",
    "            fout.write('{} {}\\n'.format(word, freq))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
